{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2020-09-07_boosting_titanic.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"authorship_tag":"ABX9TyN+AtgMaiWkk+XYqHO/uIqu"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"0pPF85ik-4Ct","colab_type":"text"},"source":["# titanic data로 부스트 총 정리!"]},{"cell_type":"code","metadata":{"id":"SUFOcSgm51lY","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/gdrive', force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WXn9Vc1S6UI3","colab_type":"code","colab":{}},"source":["import pandas as pd\n","\n","titanic = pd.read_csv('/gdrive/My Drive/data/titanic.csv')\n","display(data.head())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2QXzIAMt-m9a","colab_type":"code","colab":{}},"source":["# 업로드 방식\n","\n","from google.colab import files\n","uploaded = files.upload()\n","import io\n","import pandas as pd\n","\n","data = pd.read_csv(io.BytesIO(uploaded['titanic.csv']))\n","display(data.head())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TKgUqCDG-qSi","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np\n","from sklearn.metrics import accuracy_score\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IX93c89TAMjn","colab_type":"code","colab":{}},"source":["# data에 대한 정보 확인\n","data.info()\n","\n","# 891개의 데이터 Age, Cabin에 null값이 있음"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tX1-v7P2A-0K","colab_type":"code","colab":{}},"source":["y_data = data['Survived']\n","data.drop(labels='Survived', axis=1, inplace=True)\n","display(data.head())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U7LvpCNABaVt","colab_type":"code","colab":{}},"source":["# 필요없는 변수 날리기\n","drop_columns = ['PassengerId', 'Name','Age','SibSp', 'Ticket','Cabin','Parch','Embarked']\n","data.drop(labels=drop_columns, axis=1, inplace=True)\n","display(data.head())\n","\n","# Age 넣어줘도 무방 단, 실수형이기 때문에 카테고리형으로 변환해주는 것이 좋음 why??"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fBNdTaaaCNJ7","colab_type":"code","colab":{}},"source":["# 성별 원 핫 인코딩\n","data=pd.get_dummies(data, columns=['Sex'])\n","data.fillna(value=0.0, inplace=True)\n","display(data.head())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"56OE_l4gDUvk","colab_type":"code","colab":{}},"source":["# train, test셋 나눠주기\n","state = 42\n","test_size=0.30\n","\n","X_train, X_test, y_train, y_test = train_test_split(data, y_data, test_size=test_size, random_state=state)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X5XDzE5qN-we","colab_type":"text"},"source":["# Gradient Boosting"]},{"cell_type":"code","metadata":{"id":"CXBjs4MrDpdq","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import GridSearchCV\n","from sklearn.ensemble import GradientBoostingClassifier"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jaMbQOV_D0_Z","colab_type":"code","colab":{}},"source":["# Grid Search를 통해 최적의 파라미터 값을 찾아봅시다\n","parameters = {\n","    \"learning_rate\":[0.01,0.025,0.05,0.075,0.1,0.15,0.2],\n","    \"max_depth\":[3,5,8],\n","    \"n_estimators\":[10,50,100]\n","}\n","\n","gb_cv = GridSearchCV(GradientBoostingClassifier(), param_grid=parameters, cv=5, n_jobs=-1)\n","gb_cv.fit(X_train, y_train)\n","\n","print('final params', gb_cv.best_params_)\n","print('best score', gb_cv.best_score_)\n","\n","cv_result_df = pd.DataFrame(gb_cv.cv_results_)\n","cv_result_df.sort_values(by=['rank_test_score'], inplace=True)\n","cv_result_df[['params', 'mean_test_score', 'rank_test_score']].head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6vmVLWOSG7aJ","colab_type":"code","colab":{}},"source":["print(cv_result_df.iloc[:,0:6])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J7R8kAz9FXmm","colab_type":"code","colab":{}},"source":["# classification_report 만들기\n","from sklearn.metrics import classification_report\n","\n","gb_clf2 = GradientBoostingClassifier(n_estimators=50, learning_rate=0.2, max_depth=5, random_state=0)   # 위에서 구한 최적값을 넣어주고\n","gb_clf2.fit(X_train, y_train)               # 트레인 데이터를 학습 시킨 후\n","predictions = gb_clf2.predict(X_test)       # 테스트 값 예측\n","\n","print('Classification Report')\n","print(classification_report(y_test, predictions))   # 실제값과 예측값을 비교한 리포트 뽑아보기 이 모델은 81%의 성능을 보인다"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EwAL1ta6GrUp","colab_type":"code","colab":{}},"source":["# 변수 중요도를 그래프로 그려봅시다\n","feature_imp=pd.Series(gb_clf2.feature_importances_, index=data.columns).sort_values(ascending=True) # 모델의 변수 중요도를 시리즈에 넣어주고 sort_values를 해줌\n","print(feature_imp)\n","feature_imp.plot(kind='barh', grid=True, figsize=(5,5))\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ftgjus1nNkKj","colab_type":"text"},"source":["# XGBoosting"]},{"cell_type":"code","metadata":{"id":"lfi2FcDtOC9u","colab_type":"code","colab":{}},"source":["from xgboost import plot_importance\n","from xgboost import XGBClassifier"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lLeD0MbHOU6s","colab_type":"code","colab":{}},"source":["xgg = XGBClassifier()\n","\n","# Grid Search를 통해 최적의 파라미터 값을 찾아봅시다\n","parameters = {\n","    \"learning_rate\":[0.01,0.025,0.05,0.075,0.1,0.15,0.2],  # 0.01나 0.02 를 많이 씀\n","    \"max_depth\":[3,5,8],\n","    \"n_estimators\":[10,50,100]\n","}\n","\n","xgg_cv = GridSearchCV(xgg, param_grid=parameters, cv=5, scoring='accuracy', n_jobs=1)\n","xgg_cv.fit(X_train, y_train)\n","\n","print('final params', xgg_cv.best_params_)\n","print('best score', xgg_cv.best_score_)\n","\n","cv_result_df = pd.DataFrame(xgg_cv.cv_results_)\n","cv_result_df.sort_values(by=['rank_test_score'], inplace=True)\n","cv_result_df[['params', 'mean_test_score', 'rank_test_score']].head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sx-CLPEYO6M2","colab_type":"code","colab":{}},"source":["# classification_report 만들기\n","from sklearn.metrics import classification_report\n","\n","xgg_clf2 = XGBClassifier(n_estimators=100, learning_rate=0.2, max_depth=8, random_state=0)   # 위에서 구한 최적값을 넣어주고\n","\n","X_train = pd.DataFrame(X_train, columns=data.columns)\n","X_test = pd.DataFrame(X_test, columns=data.columns)\n","\n","xgg_clf2.fit(X_train, y_train)               # 트레인 데이터를 학습 시킨 후\n","predictions = xgg_clf2.predict(X_test)       # 테스트 값 예측\n","\n","print('Classification Report')\n","print(classification_report(y_test, predictions))   # 실제값과 예측값을 비교한 리포트 뽑아보기 이 모델은 81%의 성능을 보인다"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pSgA2OgbQqhQ","colab_type":"code","colab":{}},"source":["fscore = xgg_clf2.get_booster().get_fscore()\n","score_f = sorted(fscore.items(), key=(lambda x:x[1]), reverse=True)\n","print(score_f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F69qgVM_SjX5","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","plot_importance(xgg_clf2)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-mUbwoYYS5CD","colab_type":"text"},"source":["# Light GBM"]},{"cell_type":"code","metadata":{"id":"-f0k5DCsTtYi","colab_type":"code","colab":{}},"source":["from lightgbm import LGBMClassifier, plot_importance"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ec4TFRW_Tysf","colab_type":"code","colab":{}},"source":["lb = LGBMClassifier()\n","\n","# Grid Search를 통해 최적의 파라미터 값을 찾아봅시다\n","parameters = {\n","    \"learning_rate\":[0.01,0.025,0.05,0.075,0.1,0.15,0.2],  # 0.01나 0.02 를 많이 씀\n","    \"max_depth\":[1,2,3,4],                                  # max_depth는 num_leaves에 영향을 받아서 변수 설정이 중요\n","    \"n_estimators\":[10,50,100]                              # num_leaves = 31이 default (max_depth)**2 -1 <= 31(num_leaves)\n","}\n","\n","lgb_cv = GridSearchCV(lb, param_grid=parameters, cv=5, scoring='accuracy', n_jobs=1)\n","lgb_cv.fit(X_train, y_train)\n","\n","print('final params', lgb_cv.best_params_)\n","print('best score', lgb_cv.best_score_)\n","\n","cv_result_df = pd.DataFrame(lgb_cv.cv_results_)\n","cv_result_df.sort_values(by=['rank_test_score'], inplace=True)\n","cv_result_df[['params', 'mean_test_score', 'rank_test_score']].head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C0FDdw9zUM7U","colab_type":"code","colab":{}},"source":["# classification_report 만들기\n","from sklearn.metrics import classification_report\n","\n","LG_clf2 = LGBMClassifier(n_estimators=50, learning_rate=0.025, max_depth=4, random_state=0)   # 위에서 구한 최적값을 넣어주고\n","\n","X_train = pd.DataFrame(X_train, columns=data.columns)\n","X_test = pd.DataFrame(X_test, columns=data.columns)\n","\n","LG_clf2.fit(X_train, y_train)               # 트레인 데이터를 학습 시킨 후\n","predictions = LG_clf2.predict(X_test)       # 테스트 값 예측\n","\n","print('Classification Report')\n","print(classification_report(y_test, predictions))   # 실제값과 예측값을 비교한 리포트 뽑아보기 이 모델은 81%의 성능을 보인다"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MwMZRWfAU8yi","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","plot_importance(LG_clf2)\n","plt.show()"],"execution_count":null,"outputs":[]}]}